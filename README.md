# ğŸŸ¢ Real-Time Motion Detection (Classic CV)

Real-time **motion detection and bounding box extraction** using **classical computer vision techniques** (no deep learning).

This project detects motion from a webcam feed using **frame differencing**, cleans the motion mask with **morphological operations**, and draws a **single bounding box around the dominant moving object** in the scene.

---

## âœ¨ Features

- Real-time webcam inference  
- Motion detection via **frame differencing**  
- Noise reduction with **Gaussian blur**  
- Binary motion mask via **thresholding**  
- Mask cleanup using **morphological operations**  
- **Largest motion region selection** (single target)  
- Bounding box visualization  
- FPS overlay for performance monitoring  
- No ML / DL models â€” **pure OpenCV**

---

## ğŸ§  Core Idea

Motion is defined as **pixel-wise change between consecutive frames**.

### Pipeline Overview

1. Capture frame from webcam  
2. Convert to grayscale  
3. Apply Gaussian blur (noise reduction)  
4. Compute **absolute difference** with previous frame  
5. Threshold the difference image to obtain a motion mask  
6. Apply morphological operations (open â†’ close â†’ dilate)  
7. Extract contours  
8. Select **largest contour** as the primary moving object  
9. Draw bounding box  
10. Display FPS and output frame  

This approach is lightweight, fast, and ideal for understanding **classical motion detection fundamentals**.

---

## ğŸ“ Project Structure

```
motion-detection/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ inference.py          # Main inference script
â”‚
â”œâ”€â”€ out/
â”‚   â””â”€â”€ test_inference.png    # Example output screenshot
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â””â”€â”€ venv/                     # (ignored by git)
```

---

## ğŸ–¥ï¸ Example Output

See the example screenshot below:

- Green bounding box â†’ dominant moving object  
- Blue text â†’ real-time FPS  

![Example Output](out/test_inference.png)

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run inference

```bash
python src/inference.py
```

### 3ï¸âƒ£ Controls

- Press **q** to quit

---

## âš™ï¸ Key Parameters

You can tune these parameters inside `inference.py`:

| Parameter | Purpose |
|---------|--------|
| `thresh = 30` | Motion sensitivity |
| `kernel = (7, 7)` | Morphology strength |
| `MIN_AREA = 500` | Noise filtering |
| Gaussian blur `(5,5)` | Reduces sensor noise |

Adjust these values depending on:
- Lighting conditions  
- Camera quality  
- Desired motion sensitivity  

---

## âš ï¸ Known Limitations

- Sensitive to sudden global illumination changes  
- Camera must remain mostly static  
- Very fast motion may cause motion trails  
- Designed for **single dominant motion target**  

These are inherent limitations of frame differencing methods.

---

## ğŸ”§ Possible Improvements

- Bounding box smoothing (EMA)  
- Multi-object tracking  
- ROI-based motion filtering  
- 3-frame differencing  
- Background subtraction comparison (MOG2 / KNN)

---

## ğŸ¯ Why This Project Matters

This project demonstrates:

- Understanding of **classical computer vision pipelines**  
- Ability to design and debug real-time systems  
- Strong fundamentals before deep learning  
- Clean engineering-oriented implementation  

A solid foundation before moving to:
- Optical flow  
- Object tracking  
- Deep learningâ€“based detection  

---

## ğŸ§‘â€ğŸ’» Author

Built by **Emin Ã‡aÄŸan ApaydÄ±n**

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.